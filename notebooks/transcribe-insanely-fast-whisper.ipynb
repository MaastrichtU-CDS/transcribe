{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86dd56b3-a5a8-497c-8d39-8f0f9bb699c9",
   "metadata": {},
   "source": [
    "# insanely-fast-whisper notebook\n",
    "\n",
    "A Jupyter notebook interface for the 'insanely-fast-whisper' command-line tool, providing high-speed transcription and speaker diarization with export capabilities to Word documents.\n",
    "\n",
    "visit https://github.com/Vaibhavs10/insanely-fast-whisper for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94363b",
   "metadata": {},
   "source": [
    "#### HuggingFace user agreements!\n",
    "To run this notebook, you will need the following:\n",
    "\n",
    "A Hugging Face account: [Create an account](https://huggingface.co/settings/tokens)\n",
    "\n",
    "A Hugging Face authentication token: [Generate your token here](https://huggingface.co/settings/tokens) \n",
    "\n",
    "â†’ Enter this token in the notebook under HUGGINGFACE_AUTH_TOKEN.\n",
    "Acceptance of the following user agreements:\n",
    "- [Pyannote Speaker Diarization 3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "- [Pyannote Segmentation 3.0](https://hf.co/pyannote/segmentation-3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aceb9e1-eafa-4c8f-98e1-0bd6014adef1",
   "metadata": {},
   "source": [
    "# Quickrun for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768cf44-8219-4275-b623-0d3aad2b7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "\n",
    "# set these 3 variables and run all!\n",
    "# if you want to change the language, change it at \"2. Transcribe\"\n",
    "os.environ[\"HUGGINGFACE_AUTH_TOKEN\"] = \"hf_dqNMswjtIbBq....\"\n",
    "extensions = [\"mp3\", \"WMA\", \"wma\"]  # List of extensions\n",
    "path_audio = '/work/speech/...'\n",
    "\n",
    "# Use glob to match multiple extensions\n",
    "files = []\n",
    "for ext in extensions:\n",
    "    path_audio_regex = f\"{path_audio}*.{ext}\"  # glob does not use regex\n",
    "    files.extend(glob.glob(path_audio_regex))\n",
    "\n",
    "length = len(files)\n",
    "print(f\"The following {length} files will be transcribed: \\n{files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fcae71-1c93-439a-9f49-591d2de94dc3",
   "metadata": {},
   "source": [
    "### 1. Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05ba2a-2054-4d8d-a86f-50b85ba44751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pipx\n",
    "!pipx install insanely-fast-whisper==0.0.15 --force\n",
    "!pip install python-docx\n",
    "\n",
    "# Workaround for insanely-fast-whisper (0.0.14) \n",
    "# replace numpy=2.0.0 as it is not compatible with all modules\n",
    "# !pipx inject insanely-fast-whisper numpy==1.26.4 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e54b25-7262-4148-a43c-85a1458004ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can uncomment the following code as an alternative method if you prefer not to set your token directly in the notebook.\n",
    "# Run this cell, copy paste your huggingface token and press enter\n",
    "\n",
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# if not os.environ.get(\"HUGGINGFACE_AUTH_TOKEN\"):\n",
    "#     _set_env(\"HUGGINGFACE_AUTH_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06fa75-ad62-4370-9790-281b19ef3284",
   "metadata": {},
   "source": [
    "### 2. Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9228aad-2df2-4d02-9c7e-bfe60c3ce4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "LANGUAGE = \"da\"\n",
    "NUM_SPEAKERS = 2\n",
    "TASK = \"transcribe\"\n",
    "DIARIZATION_MODEL = \"pyannote/speaker-diarization-3.1\"\n",
    "HUGGINGFACE_AUTH_TOKEN = os.environ['HUGGINGFACE_AUTH_TOKEN']\n",
    "\n",
    "def transcribe(file_name):\n",
    "    TRANSCRIPT_PATH = os.path.splitext(file_name)[0]+\"-transcription.json\"\n",
    "    FILE_NAME = re.escape(file_name)\n",
    "    TRANSCRIPT_PATH = re.escape(TRANSCRIPT_PATH)    \n",
    "    \n",
    "    # workaround, current MPLBACKEND default does not work\n",
    "    os.environ['MPLBACKEND'] = 'svg'\n",
    "    # !echo $MPLBACKEND\n",
    "    !insanely-fast-whisper --file-name {FILE_NAME} --transcript-path {TRANSCRIPT_PATH} --language {LANGUAGE} --task {TASK} --diarization_model {DIARIZATION_MODEL} --hf-token {HUGGINGFACE_AUTH_TOKEN}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e467c-cacc-4f6f-9b49-190028f74b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(files):\n",
    "    print(f\"file {idx+1} of {length} file={file}\")\n",
    "    transcribe(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1c6c9-7fff-4e6e-87a5-e5c4eb5b88c9",
   "metadata": {},
   "source": [
    "### 3. Convert transcriptions to Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899ce9f-a4e8-41a2-8f9f-820256f192ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "\n",
    "def diarization_to_docx_edit(audio_file_diarization):\n",
    "\n",
    "    audio_file_basename = os.path.basename(audio_file_diarization)\n",
    "    \n",
    "    doc = Document()\n",
    "    \n",
    "    paragraph = doc.add_paragraph()\n",
    "    paragraph.add_run(audio_file_basename).bold = True\n",
    "    \n",
    "    paragraph_format = paragraph.paragraph_format\n",
    "    paragraph_format.alignment\n",
    "    paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    f = open(audio_file_diarization, 'r', encoding=\"utf-8\")\n",
    "\n",
    "    data = json.load(f)\n",
    "\n",
    "    for entry in data[\"speakers\"]:\n",
    "        paragraph = doc.add_paragraph()\n",
    "        paragraph.add_run(str(entry[\"timestamp\"]) + \"\\n\")\n",
    "        paragraph.add_run(str(entry[\"speaker\"])  + \"\\n\")\n",
    "        paragraph.add_run(str(entry[\"text\"]).strip())\n",
    "\n",
    "            \n",
    "    docx_filename = audio_file_diarization.replace(\".json\", \"_edit.docx\")\n",
    "    doc.save(docx_filename)\n",
    "\n",
    "\n",
    "# absolute path containing the json diarization files\n",
    "extension = \"json\"\n",
    "path_json_regex = r'' + re.escape(path_audio) + '*.' + re.escape(extension)\n",
    "files_json = glob.glob(path_json_regex)\n",
    "length_json = len(files_json)\n",
    "\n",
    "print(f\"The following {length_json} files will be converted to docx {files_json}\")\n",
    "\n",
    "for idx, file in enumerate(files_json):\n",
    "    print(f\"file {idx+1} of {length} file={file}\")\n",
    "    diarization_to_docx_edit(file)\n",
    "print(f\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
